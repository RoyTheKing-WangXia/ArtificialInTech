{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Roywangxixixixixia/ArtificialInTech/blob/main/Deep_Learning_Reproducibility_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Algorithm steps\n",
        "\n",
        "# Step 1: Load the dataset\n",
        "    dataset = load_dataset()\n",
        "\n",
        "# Step 2: Split the dataset into training and testing sets\n",
        "    train_data, test_data = split_dataset(dataset)\n",
        "\n",
        "# Step 3: Preprocess the data\n",
        "    train_data_processed = preprocess_data(train_data)\n",
        "    test_data_processed = preprocess_data(test_data)\n",
        "\n",
        "# Step 4: Train the model\n",
        "    model = train_model(train_data_processed)\n",
        "\n",
        "# Step 5: Evaluate the model on the test set\n",
        "    test_accuracy = evaluate_model(model, test_data_processed)\n",
        "\n",
        "# Step 6: Calculate the neuron activations for each sample in the test set\n",
        "    def calculate_activations(model, test_data_processed):\n",
        "        neuron_activations = []\n",
        "        for sample in test_data_processed:\n",
        "            activations = model.forward(sample)\n",
        "            neuron_activations.append(activations)\n",
        "        return neuron_activations\n",
        "\n",
        "# Step 7: Compute the exclusivity scores for each neuron\n",
        "    def calculate_exclusivity_scores(neuron_activations):\n",
        "        num_samples = len(neuron_activations)\n",
        "        num_neurons = neuron_activations[0].shape[0]\n",
        "        neuron_exclusivity_scores = np.zeros(num_neurons)\n",
        "        for neuron_idx in range(num_neurons):\n",
        "            activations = np.zeros(num_samples)\n",
        "            for sample_idx in range(num_samples):\n",
        "                activations[sample_idx] = neuron_activations[sample_idx][neuron_idx]\n",
        "            exclusivity_score = calculate_exclusivity_score(activations)\n",
        "            neuron_exclusivity_scores[neuron_idx] = exclusivity_score\n",
        "        return neuron_exclusivity_scores\n",
        "\n",
        "    def calculate_exclusivity_score(activations):\n",
        "        activation_freq = np.bincount(activations)\n",
        "        num_unique_activations = np.count_nonzero(activation_freq)\n",
        "        if num_unique_activations == 1:\n",
        "            exclusivity_score = 0\n",
        "        else:\n",
        "            max_activation_freq = np.max(activation_freq)\n",
        "            exclusivity_score = 1 - (max_activation_freq / len(activations))\n",
        "        return exclusivity_score\n",
        "\n",
        "# Step 8: Select the most exclusive neurons\n",
        "    def select_neurons(neuron_exclusivity_scores, num_neurons_to_select):\n",
        "        sorted_indices = np.argsort(neuron_exclusivity_scores)\n",
        "        selected_neurons = sorted_indices[:num_neurons_to_select]\n",
        "        return selected_neurons\n",
        "\n",
        "# Step 9: Use the selected neurons to reconstruct the input data\n",
        "    def reconstruct_data(model, test_data_processed, selected_neurons):\n",
        "        reconstructed_data = []\n",
        "        for sample in test_data_processed:\n",
        "            activations = model.forward(sample)\n",
        "            reconstructed_activations = np.zeros_like(activations)\n",
        "            reconstructed_activations[selected_neurons] = activations[selected_neurons]\n",
        "            reconstructed_sample = model.backward(reconstructed_activations)\n",
        "            reconstructed_data.append(reconstructed_sample)\n",
        "        return reconstructed_data\n",
        "\n",
        "# Step 10: Evaluate the quality of the reconstructed data\n",
        "    def evaluate_reconstruction(reconstructed_data, test_data_processed):\n",
        "        reconstruction_errors = []\n",
        "        for i in range(len(reconstructed_data)):\n",
        "            reconstruction_error = calculate_reconstruction_error(reconstructed_data[i], test_data_processed[i])\n",
        "            reconstruction_errors.append(reconstruction_error)\n",
        "        return np.array(reconstruction_errors)\n",
        "\n",
        "    def calculate_reconstruction_error(reconstructed_sample, original_sample):\n",
        "        return np.linalg.norm(reconstructed_sample - original_sample)\n",
        "\n",
        "# Step 11: Analyze the security boundary of the reconstruction by comparing the reconstruction quality with the number of selected neurons\n",
        "    def analyze_security_boundary(reconstruction_quality, selected_neurons):\n",
        "        sorted_indices = np.argsort(selected_neurons)\n",
        "        sorted_quality = reconstruction_quality[sorted_indices]\n",
        "        num_neurons = len(selected_neurons)\n",
        "        num_samples = len(reconstruction_quality)\n",
        "        security_boundary = np.zeros(num_neurons)\n",
        "        for i in range(num_neurons):\n",
        "            threshold = sorted_quality[int(num_samples*(i+1)/num_neurons)-1]\n",
        "            security_boundary[i] = threshold\n",
        "        return security_boundary\n",
        "\n",
        "# Step 12: Visualize the results\n",
        "    def visualize_results(reconstruction_quality, selected_neurons, security_boundary):\n",
        "        # Plot the reconstruction quality as a function of the number of selected neurons\n",
        "        plt.plot(range(len(selected_neurons)), reconstruction_quality, label=\"Reconstruction Quality\")\n",
        "        # Plot the security\n",
        "\n"
      ],
      "metadata": {
        "id": "u5ha9tFea20O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "Zjq6npSKlL2w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torchvision.transforms as T\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision.utils import make_grid\n",
        "from torchvision.utils import save_image\n",
        "from IPython.display import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch.optim as optim\n"
      ],
      "metadata": {
        "id": "lhEkMqG0lODN"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Steps 1 - 3"
      ],
      "metadata": {
        "id": "Z11XzoXejR9U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image_size = 8\n",
        "DATA_DIR = 'content/retinamnist.npz'\n",
        "data = np.load('/content/retinamnist.npz')\n",
        "X_train = data['train_images']\n",
        "X_train_label = torch.from_numpy(data['train_labels']).reshape(1080)\n",
        "print(f\"Shape of training data: {X_train.shape}\")\n",
        "print(f\"Shape of training data: {X_train_label.shape}\")\n",
        "print(f\"Data type: {type(X_train)}\")\n",
        "print(f\"Data type: {type(X_train_label)}\")\n",
        "print(X_train_label)"
      ],
      "metadata": {
        "id": "Bhe8Na2y6Sj0",
        "outputId": "34fcbdf7-291c-4f57-c3aa-0248a0129746",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of training data: (1080, 28, 28, 3)\n",
            "Shape of training data: torch.Size([1080])\n",
            "Data type: <class 'numpy.ndarray'>\n",
            "Data type: <class 'torch.Tensor'>\n",
            "tensor([0, 0, 0,  ..., 2, 2, 3], dtype=torch.uint8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transform = T.Compose([\n",
        "                        T.ToPILImage(),\n",
        "                        T.Resize(image_size),\n",
        "                        #T.RandomResizedCrop(image_size),\n",
        "                        T.ToTensor()])\n",
        "\n",
        "class croppedDataset(Dataset):\n",
        "    'Characterizes a dataset for PyTorch'\n",
        "    def __init__(self, ims):\n",
        "        'Initialization'\n",
        "        self.ims = ims\n",
        "    def __len__(self):\n",
        "        'Denotes the total number of samples'\n",
        "        return len(self.ims)\n",
        "    def __getitem__(self, index):\n",
        "        'Generates one sample of data'\n",
        "        # Select sample\n",
        "        image = self.ims[index]\n",
        "        X = transform(image)\n",
        "        return X\n",
        "        \n",
        "def show_images(images, nmax=8):\n",
        "    fig, ax = plt.subplots(figsize=(28, 28))\n",
        "    ax.set_xticks([]); ax.set_yticks([])\n",
        "    ax.imshow(make_grid((images.detach()[:nmax]), nrow=8).permute(1, 2, 0))\n",
        "\n",
        "def show_batch(dl, nmax=8):\n",
        "    for images in dl:\n",
        "        show_images(images, nmax)\n",
        "        break\n",
        "\n",
        "batch_size = 8\n",
        "cropped_train_dataset = croppedDataset(ims=X_train)\n",
        "\n",
        "\n",
        "# train_dl_s = X_train\n",
        "# train_dl_label_s = X_train_label\n",
        "\n",
        "# for i in range(0,len(X_train)):\n",
        "#   train_dl_s[i] = transform(X_train[i]) \n",
        "#   train_dl_label_s[i] = transform(X_train_label[i])\n",
        "\n",
        "train_dl = DataLoader(cropped_train_dataset, batch_size, shuffle=True)\n",
        "train_dl_label = DataLoader(X_train_label, batch_size, shuffle=True)\n",
        "\n",
        "show_batch(train_dl)"
      ],
      "metadata": {
        "id": "FTPLBm576Aud",
        "outputId": "f736e163-b39a-4bc7-d893-d16b2389a655",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        }
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<torch.utils.data.dataloader.DataLoader object at 0x7f2cddb952b0>\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2800x2800 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 4"
      ],
      "metadata": {
        "id": "kbdyqNSEk9ia"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "      super(Net, self).__init__()\n",
        "\n",
        "      self.fc1 = nn.Linear(8, 512)\n",
        "      self.fc2 = nn.Linear(512, 32)\n",
        "      self.fc3 = nn.Linear(32, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "      x = self.fc1(x)\n",
        "      # Use the rectified-linear activation function over x\n",
        "      x = F.relu(x)\n",
        "\n",
        "      x = self.fc2(x)\n",
        "      # Use the rectified-linear activation function over x\n",
        "      x = F.relu(x)\n",
        "\n",
        "      x = self.fc3(x)\n",
        "\n",
        "      # Apply softmax to x\n",
        "      output = F.log_softmax(x, dim=1)\n",
        "      return output\n",
        "    \n",
        "net = Net()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.005, momentum=0.9)\n",
        "for epoch in range(10):\n",
        "    running_loss = 0.0\n",
        "for i, data in enumerate(train_dl, 0):\n",
        "    inputs = data\n",
        "for i, data in enumerate(train_dl_label, 0):\n",
        "    labels = data\n",
        "    \n",
        "# Zero the parameter gradients\n",
        "optimizer.zero_grad()\n",
        "\n",
        "# Forward + backward + optimize\n",
        "outputs = net(inputs)\n",
        "print(outputs)\n",
        "print(labels)\n",
        "print(f\"Shape of training data: {outputs.shape}\")\n",
        "print(f\"Shape of training data: {labels.shape}\")\n",
        "loss = criterion(outputs, labels)\n",
        "loss.backward()\n",
        "optimizer.step()\n",
        "\n",
        "# Print statistics\n",
        "running_loss += loss.item()\n",
        "if i % 100 == 99:  # Print every 2000 mini-batches\n",
        "      print('[%d, %5d] loss: %.3f' %\n",
        "           (epoch + 1, i + 1, running_loss / 2000))\n",
        "      running_loss = 0.0"
      ],
      "metadata": {
        "id": "iYBQyOAIfViT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3be34a83-0462-4422-e3ae-258be07089ae"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[[-1.0976],\n",
            "          [-1.1031],\n",
            "          [-1.1105],\n",
            "          [-1.1168],\n",
            "          [-1.1181],\n",
            "          [-1.1143],\n",
            "          [-1.1058],\n",
            "          [-1.0977]],\n",
            "\n",
            "         [[-1.0996],\n",
            "          [-1.0976],\n",
            "          [-1.0963],\n",
            "          [-1.0947],\n",
            "          [-1.0940],\n",
            "          [-1.0944],\n",
            "          [-1.0968],\n",
            "          [-1.0992]],\n",
            "\n",
            "         [[-1.0987],\n",
            "          [-1.0951],\n",
            "          [-1.0892],\n",
            "          [-1.0847],\n",
            "          [-1.0841],\n",
            "          [-1.0873],\n",
            "          [-1.0932],\n",
            "          [-1.0989]]],\n",
            "\n",
            "\n",
            "        [[[-1.0994],\n",
            "          [-1.0989],\n",
            "          [-1.1007],\n",
            "          [-1.1035],\n",
            "          [-1.1036],\n",
            "          [-1.1015],\n",
            "          [-1.0991],\n",
            "          [-1.0983]],\n",
            "\n",
            "         [[-1.0991],\n",
            "          [-1.0990],\n",
            "          [-1.0984],\n",
            "          [-1.0983],\n",
            "          [-1.0982],\n",
            "          [-1.0979],\n",
            "          [-1.0987],\n",
            "          [-1.0990]],\n",
            "\n",
            "         [[-1.0973],\n",
            "          [-1.0979],\n",
            "          [-1.0967],\n",
            "          [-1.0940],\n",
            "          [-1.0940],\n",
            "          [-1.0964],\n",
            "          [-1.0981],\n",
            "          [-1.0986]]],\n",
            "\n",
            "\n",
            "        [[[-1.1005],\n",
            "          [-1.1003],\n",
            "          [-1.1034],\n",
            "          [-1.1015],\n",
            "          [-1.1043],\n",
            "          [-1.1081],\n",
            "          [-1.1020],\n",
            "          [-1.0978]],\n",
            "\n",
            "         [[-1.0993],\n",
            "          [-1.0984],\n",
            "          [-1.0969],\n",
            "          [-1.0965],\n",
            "          [-1.0959],\n",
            "          [-1.0965],\n",
            "          [-1.0981],\n",
            "          [-1.0986]],\n",
            "\n",
            "         [[-1.0961],\n",
            "          [-1.0971],\n",
            "          [-1.0955],\n",
            "          [-1.0978],\n",
            "          [-1.0957],\n",
            "          [-1.0913],\n",
            "          [-1.0958],\n",
            "          [-1.0995]]],\n",
            "\n",
            "\n",
            "        [[[-1.1005],\n",
            "          [-1.0996],\n",
            "          [-1.1059],\n",
            "          [-1.1108],\n",
            "          [-1.1107],\n",
            "          [-1.1078],\n",
            "          [-1.1010],\n",
            "          [-1.0972]],\n",
            "\n",
            "         [[-1.0998],\n",
            "          [-1.0992],\n",
            "          [-1.0967],\n",
            "          [-1.0963],\n",
            "          [-1.0981],\n",
            "          [-1.0994],\n",
            "          [-1.1007],\n",
            "          [-1.0986]],\n",
            "\n",
            "         [[-1.0955],\n",
            "          [-1.0970],\n",
            "          [-1.0932],\n",
            "          [-1.0889],\n",
            "          [-1.0872],\n",
            "          [-1.0887],\n",
            "          [-1.0941],\n",
            "          [-1.1001]]],\n",
            "\n",
            "\n",
            "        [[[-1.0982],\n",
            "          [-1.0993],\n",
            "          [-1.1032],\n",
            "          [-1.1070],\n",
            "          [-1.1091],\n",
            "          [-1.1059],\n",
            "          [-1.1009],\n",
            "          [-1.0996]],\n",
            "\n",
            "         [[-1.0995],\n",
            "          [-1.0988],\n",
            "          [-1.0980],\n",
            "          [-1.0978],\n",
            "          [-1.0971],\n",
            "          [-1.0974],\n",
            "          [-1.0978],\n",
            "          [-1.0982]],\n",
            "\n",
            "         [[-1.0982],\n",
            "          [-1.0977],\n",
            "          [-1.0946],\n",
            "          [-1.0911],\n",
            "          [-1.0897],\n",
            "          [-1.0925],\n",
            "          [-1.0972],\n",
            "          [-1.0980]]],\n",
            "\n",
            "\n",
            "        [[[-1.0990],\n",
            "          [-1.0978],\n",
            "          [-1.0972],\n",
            "          [-1.1006],\n",
            "          [-1.1032],\n",
            "          [-1.1042],\n",
            "          [-1.1015],\n",
            "          [-1.0984]],\n",
            "\n",
            "         [[-1.0984],\n",
            "          [-1.0983],\n",
            "          [-1.0987],\n",
            "          [-1.0984],\n",
            "          [-1.0997],\n",
            "          [-1.0976],\n",
            "          [-1.0970],\n",
            "          [-1.0985]],\n",
            "\n",
            "         [[-1.0984],\n",
            "          [-1.0998],\n",
            "          [-1.0999],\n",
            "          [-1.0969],\n",
            "          [-1.0930],\n",
            "          [-1.0941],\n",
            "          [-1.0973],\n",
            "          [-1.0989]]],\n",
            "\n",
            "\n",
            "        [[[-1.0985],\n",
            "          [-1.1023],\n",
            "          [-1.1079],\n",
            "          [-1.1119],\n",
            "          [-1.1124],\n",
            "          [-1.1099],\n",
            "          [-1.1019],\n",
            "          [-1.0994]],\n",
            "\n",
            "         [[-1.1003],\n",
            "          [-1.1010],\n",
            "          [-1.0994],\n",
            "          [-1.0996],\n",
            "          [-1.1000],\n",
            "          [-1.0988],\n",
            "          [-1.0997],\n",
            "          [-1.0985]],\n",
            "\n",
            "         [[-1.0971],\n",
            "          [-1.0926],\n",
            "          [-1.0886],\n",
            "          [-1.0846],\n",
            "          [-1.0837],\n",
            "          [-1.0873],\n",
            "          [-1.0942],\n",
            "          [-1.0980]]],\n",
            "\n",
            "\n",
            "        [[[-1.0976],\n",
            "          [-1.1000],\n",
            "          [-1.1035],\n",
            "          [-1.1062],\n",
            "          [-1.1078],\n",
            "          [-1.1082],\n",
            "          [-1.1016],\n",
            "          [-1.0989]],\n",
            "\n",
            "         [[-1.0997],\n",
            "          [-1.0980],\n",
            "          [-1.0961],\n",
            "          [-1.0951],\n",
            "          [-1.0963],\n",
            "          [-1.0960],\n",
            "          [-1.0975],\n",
            "          [-1.0985]],\n",
            "\n",
            "         [[-1.0985],\n",
            "          [-1.0978],\n",
            "          [-1.0963],\n",
            "          [-1.0945],\n",
            "          [-1.0918],\n",
            "          [-1.0917],\n",
            "          [-1.0967],\n",
            "          [-1.0984]]]], grad_fn=<LogSoftmaxBackward0>)\n",
            "tensor([4, 0, 3, 2, 2, 3, 0, 2], dtype=torch.uint8)\n",
            "Shape of training data: torch.Size([8, 3, 8, 1])\n",
            "Shape of training data: torch.Size([8])\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-99-b6db220c7d0f>\u001b[0m in \u001b[0;36m<cell line: 43>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Shape of training data: {outputs.shape}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Shape of training data: {labels.shape}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m   1172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1173\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1174\u001b[0;31m         return F.cross_entropy(input, target, weight=self.weight,\n\u001b[0m\u001b[1;32m   1175\u001b[0m                                \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m                                label_smoothing=self.label_smoothing)\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   3024\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3025\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_smoothing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: only batches of spatial targets supported (3D tensors) but got targets of dimension: 1"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eA1IZQD-tQQy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}